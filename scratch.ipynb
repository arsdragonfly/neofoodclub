{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.discrete.discrete_model import MNLogit\n",
    "# from statsmodels.tools.tools import add_constant\n",
    "import numpy as np\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "from collections import OrderedDict\n",
    "import pylogit as pl\n",
    "import pandas as pd\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.45115932  0.81491071 -0.25031573 -1.55576916  0.40856351\n",
      "  0.26102905 -0.53848883  0.27563455  0.8477542   0.72776987  0.19864273\n",
      "  0.17968097  1.76954774  0.0595302  -0.41408748  0.04676339 -0.50247251\n",
      " -0.50564258 -1.267766  ]\n",
      "[0.03640069 0.05715387 0.08222821 0.02833994 0.00768153 0.05477048\n",
      " 0.04725776 0.02124452 0.04795305 0.08497371 0.07536611 0.0443996\n",
      " 0.04356564 0.21360649 0.03863343 0.02405879 0.03814334 0.02202361\n",
      " 0.02195391 0.01024533]\n"
     ]
    }
   ],
   "source": [
    "n_rows = 30000\n",
    "n_teams = 20\n",
    "n_candidates = 4\n",
    "# randomly generate a n_rows and n_teams column numpy array where each row has exactly n_seats ones\n",
    "X = np.zeros((n_rows, n_teams))\n",
    "for i in range(n_rows):\n",
    "    X[i, np.random.choice(n_teams, n_candidates, replace=False)] = 1\n",
    "\n",
    "capabilities = np.concatenate([np.zeros(1), np.random.standard_normal(n_teams - 1)])\n",
    "print(capabilities)\n",
    "print(scipy.special.softmax(capabilities))\n",
    "\n",
    "# for each row, randomly choose one as the winner\n",
    "Y = np.zeros((n_rows))\n",
    "for i in range(n_rows):\n",
    "    indices = np.where(X[i, :] == 1)[0]\n",
    "    prob = scipy.special.softmax(capabilities[indices])\n",
    "    Y[i] = np.random.choice(indices, p=prob)\n",
    "# convert the data to long format\n",
    "L = np.zeros((n_rows * n_candidates, 3))\n",
    "for i in range(n_rows):\n",
    "    indices = np.where(X[i, :] == 1)[0]\n",
    "    for j, idx in enumerate(indices):\n",
    "        L[i*n_candidates + j, 0] = i\n",
    "        L[i*n_candidates + j, 1] = idx\n",
    "        L[i*n_candidates + j, 2] = 1 if Y[i] == idx else 0\n",
    "\n",
    "# exog = X\n",
    "# m = MNLogit(Y, exog)\n",
    "# m_fit = m.fit(method='powell',maxiter=10000)\n",
    "\n",
    "# print(scipy.special.softmax(capabilities[:n_candidates]))\n",
    "# print(m_fit.predict(np.concatenate([np.ones(n_candidates), np.zeros(n_teams - n_candidates)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -41,588.8308\n",
      "Initial Log-likelihood: -41,588.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsdragonfly/neofoodclub/envs/default/lib/python3.10/site-packages/scipy/optimize/_minimize.py:555: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  warn('Method %s does not use Hessian information (hess).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 1.06 seconds.\n",
      "Final log-likelihood: -36,443.1869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multinomial Logit Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>win</td>           <th>  No. Observations:  </th>   <td>30,000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>         <td>Multinomial Logit Model</td> <th>  Df Residuals:      </th>   <td>29,981</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>     <td>19</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Jan 2023</td>     <th>  Pseudo R-squ.:     </th>    <td>0.124</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:17</td>         <th>  Pseudo R-bar-squ.: </th>    <td>0.123</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AIC:</th>                 <td>72,924.374</td>        <th>  Log-Likelihood:    </th> <td>-36,443.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIC:</th>                 <td>73,082.244</td>        <th>  LL-Null:           </th> <td>-41,588.831</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_1</th>  <td>    0.5055</td> <td>    0.042</td> <td>   12.117</td> <td> 0.000</td> <td>    0.424</td> <td>    0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_2</th>  <td>    0.8211</td> <td>    0.041</td> <td>   20.121</td> <td> 0.000</td> <td>    0.741</td> <td>    0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_3</th>  <td>   -0.1547</td> <td>    0.046</td> <td>   -3.384</td> <td> 0.001</td> <td>   -0.244</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_4</th>  <td>   -1.4809</td> <td>    0.065</td> <td>  -22.784</td> <td> 0.000</td> <td>   -1.608</td> <td>   -1.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_5</th>  <td>    0.4629</td> <td>    0.042</td> <td>   11.105</td> <td> 0.000</td> <td>    0.381</td> <td>    0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_6</th>  <td>    0.3380</td> <td>    0.042</td> <td>    7.969</td> <td> 0.000</td> <td>    0.255</td> <td>    0.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_7</th>  <td>   -0.4914</td> <td>    0.048</td> <td>  -10.163</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_8</th>  <td>    0.3254</td> <td>    0.043</td> <td>    7.646</td> <td> 0.000</td> <td>    0.242</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_9</th>  <td>    0.8919</td> <td>    0.041</td> <td>   21.901</td> <td> 0.000</td> <td>    0.812</td> <td>    0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_10</th> <td>    0.7597</td> <td>    0.041</td> <td>   18.512</td> <td> 0.000</td> <td>    0.679</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_11</th> <td>    0.2939</td> <td>    0.042</td> <td>    6.918</td> <td> 0.000</td> <td>    0.211</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_12</th> <td>    0.2380</td> <td>    0.043</td> <td>    5.541</td> <td> 0.000</td> <td>    0.154</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_13</th> <td>    1.8718</td> <td>    0.041</td> <td>   45.748</td> <td> 0.000</td> <td>    1.792</td> <td>    1.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_14</th> <td>    0.0972</td> <td>    0.044</td> <td>    2.231</td> <td> 0.026</td> <td>    0.012</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_15</th> <td>   -0.3609</td> <td>    0.047</td> <td>   -7.652</td> <td> 0.000</td> <td>   -0.453</td> <td>   -0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_16</th> <td>    0.0730</td> <td>    0.044</td> <td>    1.657</td> <td> 0.097</td> <td>   -0.013</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_17</th> <td>   -0.4626</td> <td>    0.048</td> <td>   -9.582</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_18</th> <td>   -0.4609</td> <td>    0.048</td> <td>   -9.526</td> <td> 0.000</td> <td>   -0.556</td> <td>   -0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC_19</th> <td>   -1.1646</td> <td>    0.058</td> <td>  -20.172</td> <td> 0.000</td> <td>   -1.278</td> <td>   -1.051</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     Multinomial Logit Model Regression Results                    \n",
       "===================================================================================\n",
       "Dep. Variable:                         win   No. Observations:               30,000\n",
       "Model:             Multinomial Logit Model   Df Residuals:                   29,981\n",
       "Method:                                MLE   Df Model:                           19\n",
       "Date:                     Tue, 03 Jan 2023   Pseudo R-squ.:                   0.124\n",
       "Time:                             18:03:17   Pseudo R-bar-squ.:               0.123\n",
       "AIC:                            72,924.374   Log-Likelihood:            -36,443.187\n",
       "BIC:                            73,082.244   LL-Null:                   -41,588.831\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ASC_1          0.5055      0.042     12.117      0.000       0.424       0.587\n",
       "ASC_2          0.8211      0.041     20.121      0.000       0.741       0.901\n",
       "ASC_3         -0.1547      0.046     -3.384      0.001      -0.244      -0.065\n",
       "ASC_4         -1.4809      0.065    -22.784      0.000      -1.608      -1.353\n",
       "ASC_5          0.4629      0.042     11.105      0.000       0.381       0.545\n",
       "ASC_6          0.3380      0.042      7.969      0.000       0.255       0.421\n",
       "ASC_7         -0.4914      0.048    -10.163      0.000      -0.586      -0.397\n",
       "ASC_8          0.3254      0.043      7.646      0.000       0.242       0.409\n",
       "ASC_9          0.8919      0.041     21.901      0.000       0.812       0.972\n",
       "ASC_10         0.7597      0.041     18.512      0.000       0.679       0.840\n",
       "ASC_11         0.2939      0.042      6.918      0.000       0.211       0.377\n",
       "ASC_12         0.2380      0.043      5.541      0.000       0.154       0.322\n",
       "ASC_13         1.8718      0.041     45.748      0.000       1.792       1.952\n",
       "ASC_14         0.0972      0.044      2.231      0.026       0.012       0.183\n",
       "ASC_15        -0.3609      0.047     -7.652      0.000      -0.453      -0.268\n",
       "ASC_16         0.0730      0.044      1.657      0.097      -0.013       0.159\n",
       "ASC_17        -0.4626      0.048     -9.582      0.000      -0.557      -0.368\n",
       "ASC_18        -0.4609      0.048     -9.526      0.000      -0.556      -0.366\n",
       "ASC_19        -1.1646      0.058    -20.172      0.000      -1.278      -1.051\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe from L\n",
    "df = pd.DataFrame(L, columns=['round_id', 'team_id', 'win'])\n",
    "specification = OrderedDict()\n",
    "names = OrderedDict()\n",
    "teams_except_the_first = list(range(1, n_teams))\n",
    "specification[\"intercept\"] = teams_except_the_first\n",
    "names[\"intercept\"] = [f'ASC_{i}' for i in teams_except_the_first]\n",
    "mnl = pl.create_choice_model(data=df,\n",
    "                                alt_id_col='team_id',\n",
    "                                obs_id_col='round_id',\n",
    "                                choice_col='win',\n",
    "                                specification=specification,\n",
    "                                model_type=\"MNL\",\n",
    "                                names=names)\n",
    "mnl.fit_mle(np.zeros(n_teams - 1))\n",
    "mnl.get_statsmodels_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03432093, 0.05689904, 0.07800863, 0.02940248, 0.0078058 ,\n",
       "       0.05452371, 0.04812218, 0.02099694, 0.04752031, 0.08373164,\n",
       "       0.0733655 , 0.04604697, 0.04354132, 0.22308306, 0.03782329,\n",
       "       0.02392254, 0.03691993, 0.021609  , 0.02164674, 0.01071001])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.special.softmax(np.concatenate([np.zeros(1), mnl.coefs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b017891a7a1fc97a96375d3bd16ebf0f7772c2f2b1f4fac30cecf04272cb1be7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
